# Wednesday, February 24

## Liskov Substitution Principle

* Formalizes inheritances and open-closed ideas nicely
* Most of the pre- and post-conditions discussed are implicit and we'd never really write them
* But it does give a formal argument for why things that feel wrong are wrong

## How MTL works
```{cpp}
class Matrix {
	int row_, col_;
	std::vector<double> v_;
  public:
    double op(int i, int j) const {
        return v_[i*col_ + j];
    }
    
    // ...
}

Matrix op*(double a, const Matrix& A) {
    // ...
}
Matrix op*(const Matrix& A, double a) {
    return a * A;
}
Matrix op+(const Matrix& A, const Matrix& B) {
    // ...
}
Matrix op*(const Matrix& A, const Matrix& B) {
    // ...
}

int main() {
	Matrix A, B, C;
	double a = 3.14;
	C = a * A * B + C;
}
```
The guy said "we should loop it" unprompted. We want this to be equivalent to

```{cpp}
/** 
 * for i
 *  for j
 *   double t = 0;
 *   for k
 *    t += A(i,k) * A(k,j)
 *   C(i,j) = a*t + C(i,j)
 */
```

But what's actually happening is 

```{cpp}
 /**
  * Matrix T1
  * for i
  *  for j
  *   T1(i,j) = a * A(i,j)
  * Matrix T2
  * for i
  *  for j
  *   double t = 0
  *   for k
  *    t += T1(i,k) * B(k,j)
  *   T2(i,j) = t
  * Matrix T3
  * for i
  *  for j
  *   T3(i,j) = T2(i,j) + C(i,j)
  * for i
  *  for j
  *   C(i,j) = T3(i,j)
  */
```

* This is crap. The temporaries take up space, and we have to read and write too many values from memory with all the loops.
* We wrote our operators in an eager way, where everything is evaluated when called. Let's try the scaling operation lazily.

```{cpp}
class ScaledMatrix {
    Matrix& A;
    double a;
  public:
    doulbe op()(int i, int j) const {
        return a * A(i,j);
    }
}

ScaledMatrix op*(double a, Matrix& A) {
    return {A, a};
}

void Matrix::op=(ScaledMatrix& M) {
    for (int i = 0; i < row_; ++i) {
        for (int j = 0; j < col_; ++j) {
            this->(i,j) = M(i,j);
        }
    }
}
```

* So we move the time of computation to the last possible moment. This is a good start.
* But we're falling into a rabbit hole. To do ```A*B```, we'd need a ```MatrixProduct```. And for ```a * A * B```, we'd need a ```ScaledMatrixProduct```. And we'd need to rewrite the operators between all of them.
* We need to parameterize the types, like we did with the Force units.
* We want to write an ```op*()``` that can take anything that satisfies the Matrix concept.
* Templating is too powerful for ```op*()``` (it would catch ```double```s and try it for ```String```s)
* What about inheritance?

```{cpp}
struct MatrixBase {
    virtual double op()(int i, int j) const = 0;
};
```

* LSP holds here since we just wrote the interface.
* Seems like it should work.
* But we don't need to do this.
* Virtual functions can be helpful when we have dynamic knowledge, but we don't need them for static (compile-time knowledge). And that's what we have here: we know what the statements evaluated to at compile time.
* We want to avoid virtual functions when we can, because they have overhead.
* Let's try the **Curiously Recurring Template Pattern**.

## Curiously Recurring Template Pattern

```{cpp}
template <typename Derived>
struct MatrixBase {
    double op()(int i, int j) const {
        return static_cast<const Derived&>(*this)(i,j);
    }
}
```

* This calls the derived type's function without overhead.
* To inherit from this, we do

```{cpp}
class Matrix : public MatrixBase<Matrix> {
    //...
};

template <typename T>
class ScaledMatrix : public MatrixBase<ScaledMatrix> {
    MatrixBase<T>& A;
    double a;
    //...
};

template <typename T, typename U>
class MatMat : public MatrixBase<MatMat> {
    MatrixBase<T>& A;
    MatrixBase<U>& B;

};

template <typename T, typename U>
class MatSum : public MatrixBase<MatSum> {
    MatrixBase<T>& A;
    MatrixBase<U>& B;
  public:
    double op()(int i, int j) const {
        double t = 0;
        for (int k = 0; i < B.rows_; ++i) {
            t += A(i,k) * B(k,j);
        }
        return t;
    }   
};
```

* Now we can rewrite the functions in a concise way

```{cpp}
template <typename T>
ScaledMatrix<T> op*(double a, MatrixBase<T>& M) {
    return {a, M};
}

template <typename T, typename U>
MatMat<T,U> op*(const MatrixBase<T>& A, const MatrixBase<U>& B) {
    return {A, B};
}

template <typename T, typename U>
MatSum<T,U> op+(const MatrixBase<T>& A, const MatrixBase<U>& B) {
    return {A, B};
}
```

* So the operation ```(a * (A*B)) + C``` gives a ```MatSum<Matrix, ScaledMatrix<MatMat<Matrix, Matrix>>>```
* This creates an evaluation tree when we call ```MatrixBase::op()(int, int)```
* If we write it out, the evaluation is the same as the optimal expression we wrote above
* Another neat thing is that the compiler will optimize the evaluation of the expression tree
